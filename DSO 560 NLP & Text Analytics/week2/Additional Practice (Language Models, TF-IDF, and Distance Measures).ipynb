{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Practice\n",
    "\n",
    "You should complete this notebook after watching Lecture 3. You can use page 5-6 (begining with the top of page 5) of [N-gram Language Models (Jurafsky and Martin)](https://github.com/ychennay/dso-560-nlp-and-text-analytics/blob/master/week3/N-Gram%20Language%20Models%20(Jurafsky%20and%20Martin).pdf) for additional help completing the following exercises. Show your work for all exercises to receive credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Matrix for Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word.lower())\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word.lower(), tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"He eats lunch at home\",\n",
    "         \"She wants to eat dinner at home\",\n",
    "         \"He eats lunch at work\",\n",
    "         \"She wants to go home\",\n",
    "         \"He wants lunch\"]\n",
    "\n",
    "# Including START and END in every sentence of the corpus\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = 'START ' + corpus[i] + ' END'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing sentence\n",
    "for i in range(len(corpus)):\n",
    "    corpus[i] = lemmatize_sentence(corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>dinner</th>\n",
       "      <th>to</th>\n",
       "      <th>go</th>\n",
       "      <th>lunch</th>\n",
       "      <th>at</th>\n",
       "      <th>work</th>\n",
       "      <th>home</th>\n",
       "      <th>he</th>\n",
       "      <th>she</th>\n",
       "      <th>eat</th>\n",
       "      <th>want</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dinner</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start  dinner  to  go  lunch  at  work  home  he  she  eat  want  end\n",
       "start       0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "dinner      0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "to          0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "end         0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "go          0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "lunch       0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "at          0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "work        0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "home        0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "he          0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "she         0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "eat         0       0   0   0      0   0     0     0   0    0    0     0    0\n",
       "want        0       0   0   0      0   0     0     0   0    0    0     0    0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating term matrix\n",
    "tokens = []\n",
    "for sentence in corpus:\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            tokens.append(word)\n",
    "\n",
    "df = pd.DataFrame(index = list(set(tokens)),columns = list(set(tokens)))\n",
    "df.fillna(0,inplace = True)\n",
    "cols = list(df.columns) # Make a list of all of the columns in the df\n",
    "cols.pop(cols.index('end')) #Remove 'end' from list\n",
    "df = df[cols+['end']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Transition Frequency Matrix\n",
    "You may lemmatize the original documents (ie., `eats` $\\rightarrow$ `eat`, `wants` $\\rightarrow$ `want`) and ignore case.\n",
    "\n",
    "**Hint:** a transition frequency matrix is of shape $V$ x $V$, where $V$ is the number of unique words in the vocabulary of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'he', 'eat', 'lunch', 'at', 'home', 'end', 'start', 'she', 'want', 'to', 'eat', 'dinner', 'at', 'home', 'end', 'start', 'he', 'eat', 'lunch', 'at', 'work', 'end', 'start', 'she', 'want', 'to', 'go', 'home', 'end', 'start', 'he', 'want', 'lunch', 'end']\n",
      "\n",
      " All the possible Bigrams are \n",
      "[('start', 'he'), ('he', 'eat'), ('eat', 'lunch'), ('lunch', 'at'), ('at', 'home'), ('home', 'end'), ('end', 'start'), ('start', 'she'), ('she', 'want'), ('want', 'to'), ('to', 'eat'), ('eat', 'dinner'), ('dinner', 'at'), ('at', 'home'), ('home', 'end'), ('end', 'start'), ('start', 'he'), ('he', 'eat'), ('eat', 'lunch'), ('lunch', 'at'), ('at', 'work'), ('work', 'end'), ('end', 'start'), ('start', 'she'), ('she', 'want'), ('want', 'to'), ('to', 'go'), ('go', 'home'), ('home', 'end'), ('end', 'start'), ('start', 'he'), ('he', 'want'), ('want', 'lunch'), ('lunch', 'end')]\n",
      "\n",
      " Bigrams along with their frequency (transition frequency matrix)\n",
      "{('start', 'he'): 3, ('he', 'eat'): 2, ('eat', 'lunch'): 2, ('lunch', 'at'): 2, ('at', 'home'): 2, ('home', 'end'): 3, ('end', 'start'): 4, ('start', 'she'): 2, ('she', 'want'): 2, ('want', 'to'): 2, ('to', 'eat'): 1, ('eat', 'dinner'): 1, ('dinner', 'at'): 1, ('at', 'work'): 1, ('work', 'end'): 1, ('to', 'go'): 1, ('go', 'home'): 1, ('he', 'want'): 1, ('want', 'lunch'): 1, ('lunch', 'end'): 1}\n",
      "\n",
      " Unigrams along with their frequency \n",
      "{'start': 5, 'he': 3, 'eat': 3, 'lunch': 3, 'at': 3, 'home': 3, 'end': 4, 'she': 2, 'want': 3, 'to': 2, 'dinner': 1, 'work': 1, 'go': 1}\n",
      "\n",
      " Bigrams along with their probability (transition frequency matrix)\n",
      "{('start', 'he'): 0.6, ('he', 'eat'): 0.6666666666666666, ('eat', 'lunch'): 0.6666666666666666, ('lunch', 'at'): 0.6666666666666666, ('at', 'home'): 0.6666666666666666, ('home', 'end'): 1.0, ('end', 'start'): 1.0, ('start', 'she'): 0.4, ('she', 'want'): 1.0, ('want', 'to'): 0.6666666666666666, ('to', 'eat'): 0.5, ('eat', 'dinner'): 0.3333333333333333, ('dinner', 'at'): 1.0, ('at', 'work'): 0.3333333333333333, ('work', 'end'): 1.0, ('to', 'go'): 0.5, ('go', 'home'): 1.0, ('he', 'want'): 0.3333333333333333, ('want', 'lunch'): 0.3333333333333333, ('lunch', 'end'): 0.3333333333333333}\n",
      "\n",
      " The bigrams in given sentence are \n",
      "[('This', 'is'), ('is', 'my'), ('my', 'cat')]\n",
      "\n",
      "Probablility of sentence \"This is my cat\" = 0\n"
     ]
    }
   ],
   "source": [
    "def readData():\n",
    "    data = corpus\n",
    "    dat=[]\n",
    "\n",
    "    for sentence in corpus:\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            dat.append(word)\n",
    "    print(dat)\n",
    "    return dat\n",
    "\n",
    "\n",
    "\n",
    "def createBigram(data,df):\n",
    "   listOfBigrams = []\n",
    "   bigramCounts = {}\n",
    "   unigramCounts = {}\n",
    "   for i in range(len(data)-1):\n",
    "      if i < len(data) - 1 and data[i+1].islower():\n",
    "\n",
    "         listOfBigrams.append((data[i], data[i + 1]))\n",
    "\n",
    "         if (data[i], data[i+1]) in bigramCounts:\n",
    "            bigramCounts[(data[i], data[i + 1])] += 1\n",
    "            df.loc[data[i], data[i + 1]] += 1\n",
    "         else:\n",
    "            bigramCounts[(data[i], data[i + 1])] = 1\n",
    "            df.loc[data[i], data[i + 1]] = 1\n",
    "\n",
    "      if data[i] in unigramCounts:\n",
    "         unigramCounts[data[i]] += 1\n",
    "      else:\n",
    "         unigramCounts[data[i]] = 1\n",
    "   return listOfBigrams, unigramCounts, bigramCounts\n",
    "\n",
    "\n",
    "def calcBigramProb(listOfBigrams, unigramCounts, bigramCounts):\n",
    "    listOfProb = {}\n",
    "    for bigram in listOfBigrams:\n",
    "        word1 = bigram[0]\n",
    "        word2 = bigram[1]\n",
    "        listOfProb[bigram] = (bigramCounts.get(bigram))/(unigramCounts.get(word1))\n",
    "    return listOfProb\n",
    "\n",
    "data = readData()\n",
    "listOfBigrams, unigramCounts, bigramCounts = createBigram(data, df)\n",
    "\n",
    "print(\"\\n All the possible Bigrams are \")\n",
    "print(listOfBigrams)\n",
    "\n",
    "print(\"\\n Bigrams along with their frequency (transition frequency matrix)\")\n",
    "print(bigramCounts)\n",
    "\n",
    "print(\"\\n Unigrams along with their frequency \")\n",
    "print(unigramCounts)\n",
    "\n",
    "bigramProb = calcBigramProb(listOfBigrams, unigramCounts, bigramCounts)\n",
    "\n",
    "print(\"\\n Bigrams along with their probability (transition frequency matrix)\")\n",
    "print(bigramProb)\n",
    "inputList=\"This is my cat\"\n",
    "splt=inputList.split()\n",
    "outputProb1 = 1\n",
    "bilist=[]\n",
    "bigrm=[]\n",
    "\n",
    "for i in range(len(splt) - 1):\n",
    "    if i < len(splt) - 1:\n",
    "\n",
    "        bilist.append((splt[i], splt[i + 1]))\n",
    "\n",
    "print(\"\\n The bigrams in given sentence are \")\n",
    "print(bilist)\n",
    "for i in range(len(bilist)):\n",
    "    if bilist[i] in bigramProb:\n",
    "\n",
    "        outputProb1 *= bigramProb[bilist[i]]\n",
    "    else:\n",
    "\n",
    "        outputProb1 *= 0\n",
    "print('\\n' + 'Probablility of sentence \\\"This is my cat\\\" = ' + str(outputProb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dinner</th>\n",
       "      <th>to</th>\n",
       "      <th>go</th>\n",
       "      <th>lunch</th>\n",
       "      <th>at</th>\n",
       "      <th>work</th>\n",
       "      <th>home</th>\n",
       "      <th>he</th>\n",
       "      <th>she</th>\n",
       "      <th>eat</th>\n",
       "      <th>want</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dinner</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dinner  to  go  lunch  at  work  home  he  she  eat  want  end\n",
       "start        0   0   0      0   0     0     0   3    2    0     0    0\n",
       "dinner       0   0   0      0   1     0     0   0    0    0     0    0\n",
       "to           0   0   1      0   0     0     0   0    0    1     0    0\n",
       "go           0   0   0      0   0     0     1   0    0    0     0    0\n",
       "lunch        0   0   0      0   2     0     0   0    0    0     0    1\n",
       "at           0   0   0      0   0     1     2   0    0    0     0    0\n",
       "work         0   0   0      0   0     0     0   0    0    0     0    1\n",
       "home         0   0   0      0   0     0     0   0    0    0     0    3\n",
       "he           0   0   0      0   0     0     0   0    0    2     1    0\n",
       "she          0   0   0      0   0     0     0   0    0    0     2    0\n",
       "eat          1   0   0      2   0     0     0   0    0    0     0    0\n",
       "want         0   2   0      1   0     0     0   0    0    0     0    0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transition frequency matrix\n",
    "df = df.drop('start',axis = 1).drop('end',axis = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Transition Frequency Matrix into a Transition Matrix\n",
    "\n",
    "**Hint:** the rows in the transition matrix should sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dinner</th>\n",
       "      <th>to</th>\n",
       "      <th>go</th>\n",
       "      <th>lunch</th>\n",
       "      <th>at</th>\n",
       "      <th>work</th>\n",
       "      <th>home</th>\n",
       "      <th>he</th>\n",
       "      <th>she</th>\n",
       "      <th>eat</th>\n",
       "      <th>want</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dinner</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dinner        to   go     lunch        at      work      home   he  \\\n",
       "start   0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.6   \n",
       "dinner  0.000000  0.000000  0.0  0.000000  1.000000  0.000000  0.000000  0.0   \n",
       "to      0.000000  0.000000  0.5  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "go      0.000000  0.000000  0.0  0.000000  0.000000  0.000000  1.000000  0.0   \n",
       "lunch   0.000000  0.000000  0.0  0.000000  0.666667  0.000000  0.000000  0.0   \n",
       "at      0.000000  0.000000  0.0  0.000000  0.000000  0.333333  0.666667  0.0   \n",
       "work    0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "home    0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "he      0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "she     0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "eat     0.333333  0.000000  0.0  0.666667  0.000000  0.000000  0.000000  0.0   \n",
       "want    0.000000  0.666667  0.0  0.333333  0.000000  0.000000  0.000000  0.0   \n",
       "\n",
       "        she       eat      want       end  \n",
       "start   0.4  0.000000  0.000000  0.000000  \n",
       "dinner  0.0  0.000000  0.000000  0.000000  \n",
       "to      0.0  0.500000  0.000000  0.000000  \n",
       "go      0.0  0.000000  0.000000  0.000000  \n",
       "lunch   0.0  0.000000  0.000000  0.333333  \n",
       "at      0.0  0.000000  0.000000  0.000000  \n",
       "work    0.0  0.000000  0.000000  1.000000  \n",
       "home    0.0  0.000000  0.000000  1.000000  \n",
       "he      0.0  0.666667  0.333333  0.000000  \n",
       "she     0.0  0.000000  1.000000  0.000000  \n",
       "eat     0.0  0.000000  0.000000  0.000000  \n",
       "want    0.0  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transition matrix\n",
    "df = df.div(df.sum(axis=1), axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Probability of the Following Documents\n",
    "\n",
    "Assume a bi-gram language model. \n",
    "\n",
    "Hint: a valid probability is between 0 and 1. \n",
    "\n",
    "### `He wants to go home`\n",
    "**Hint**: Calculate first the probability of `He` $\\rightarrow$ `wants`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The bigrams in given sentence are \n",
      "[('he', 'want'), ('want', 'to'), ('to', 'go'), ('go', 'home')]\n",
      "\n",
      "Probablility of sentence \"He wants to go home\" = 11.11%\n"
     ]
    }
   ],
   "source": [
    "# probability of He wants to go home\n",
    "\n",
    "inputList = \"He wants to go home\"\n",
    "inputList = lemmatize_sentence(inputList)\n",
    "splt=inputList.split()\n",
    "outputProb1 = 1\n",
    "bilist=[]\n",
    "bigrm=[]\n",
    "\n",
    "for i in range(len(splt) - 1):\n",
    "    if i < len(splt) - 1:\n",
    "\n",
    "        bilist.append((splt[i], splt[i + 1]))\n",
    "\n",
    "print(\"\\n The bigrams in given sentence are \")\n",
    "print(bilist)\n",
    "for i in range(len(bilist)):\n",
    "    if bilist[i] in bigramProb:\n",
    "\n",
    "        outputProb1 *= bigramProb[bilist[i]]\n",
    "    else:\n",
    "\n",
    "        outputProb1 *= 0\n",
    "print('\\n' + 'Probablility of sentence \\\"He wants to go home\\\" = ' + str(round(outputProb1*100,2)) + '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `At to go work`\n",
    "\n",
    "**Hint**: Calculate first the probability of `At` $\\rightarrow$ `to`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The bigrams in given sentence are \n",
      "[('at', 'to'), ('to', 'go'), ('go', 'work')]\n",
      "\n",
      "Probablility of sentence \"At to go work\" = 0.0%\n"
     ]
    }
   ],
   "source": [
    "# probability of At to go work\n",
    "\n",
    "inputList=\"At to go work\"\n",
    "inputList = lemmatize_sentence(inputList)\n",
    "splt=inputList.split()\n",
    "outputProb1 = 1\n",
    "bilist=[]\n",
    "bigrm=[]\n",
    "\n",
    "for i in range(len(splt) - 1):\n",
    "    if i < len(splt) - 1:\n",
    "\n",
    "        bilist.append((splt[i], splt[i + 1]))\n",
    "\n",
    "print(\"\\n The bigrams in given sentence are \")\n",
    "print(bilist)\n",
    "for i in range(len(bilist)):\n",
    "    if bilist[i] in bigramProb:\n",
    "\n",
    "        outputProb1 *= bigramProb[bilist[i]]\n",
    "    else:\n",
    "\n",
    "        outputProb1 *= 0\n",
    "print('\\n' + 'Probablility of sentence \\\"At to go work\\\" = ' + str(round(outputProb1*100,2)) + '%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity and Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the **cosine similarity** and **Euclidean distance** of the following pairs of sentences. Do not use any 3rd party libraries (besides Numpy) to perform your calculation and show your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. *He wants candy.*\n",
    "\n",
    "B. *He wants soup.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['candy', 'he', 'soup', 'wants']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1],\n",
       "       [0, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# take two very similar sentences, should have high similarity\n",
    "# edit these sentences to become less similar, and the similarity score should decrease\n",
    "data_corpus = [\"He wants candy.\", \n",
    "               \"He wants soup.\"]\n",
    "\n",
    "X = vectorizer.fit_transform(data_corpus) \n",
    "X = X.toarray()\n",
    "print(vectorizer.get_feature_names())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity\n",
    "def cosine_similarity(A, B):\n",
    "    numerator = dot(A, B)\n",
    "    denominator = norm(A) * norm(B)\n",
    "    return numerator / denominator\n",
    "\n",
    "def cosine_distance(A,B):\n",
    "    return 1 - cosine_similarity\n",
    "\n",
    "print(round(cosine_similarity(X[0], X[1]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance\n",
    "def euclidean_distance(x,y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return np.linalg.norm(x-y)\n",
    "\n",
    "print(round(euclidean_distance(X[0], X[1]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. *He wants candy and sweets, but she wants soup.*\n",
    "\n",
    "B. *He wants soup.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'but', 'candy', 'he', 'she', 'soup', 'sweets', 'wants']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# take two very similar sentences, should have high similarity\n",
    "# edit these sentences to become less similar, and the similarity score should decrease\n",
    "data_corpus = [\"He wants candy and sweets, but she wants soup.\", \n",
    "               \"He wants soup.\"]\n",
    "\n",
    "X = vectorizer.fit_transform(data_corpus) \n",
    "X = X.toarray()\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity\n",
    "def cosine_similarity(A, B):\n",
    "    numerator = dot(A, B)\n",
    "    denominator = norm(A) * norm(B)\n",
    "    return numerator / denominator\n",
    "\n",
    "def cosine_distance(A,B):\n",
    "    return 1 - cosine_similarity\n",
    "\n",
    "print(round(cosine_similarity(X[0], X[1]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.45\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance\n",
    "def euclidean_distance(x,y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return np.linalg.norm(x-y)\n",
    "\n",
    "print(round(euclidean_distance(X[0], X[1]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain why cosine similarity is usually preferred over Euclidean distance when working within natural language processing projects.\n",
    "\n",
    "Please use your own words and provide a concrete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### your answer\n",
    "Cosine similarity utilizes the vector representation of a token where as Euclidean distance relies solely on the counts of individual tokens. Cosine similatiry scores similarity of two documents based on the angle between the vector representations by dividing the dot product of the two vectors with the norm of individual vector. Thus it normalizes for the length of the different documents.\n",
    "\n",
    "For example,\n",
    "\n",
    "document 1: he loves <br>\n",
    "document 2: he loves he loves\n",
    "\n",
    "For the following documents, the cosine similarity would be exactly 1 whereas the euclidean distance would be square root of 2 since it depends simply on the count of tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the TF-IDF vectors for the three documents below.\n",
    "\n",
    "You may use the following equations for term frequency:\n",
    "\n",
    "$$\n",
    "n(t,d)\n",
    "$$\n",
    "Where $n(t,d)$ is the number of times the term $t$ appears in document $d$.\n",
    "\n",
    "For inverse document frequency, you may use the following equation:\n",
    "\n",
    "$$\n",
    "\\frac{N}{1 + n(t)}\n",
    "$$\n",
    "Where $N$ is the total number of documents and $n(t)$ is the number of documents the term $t$ appears in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. `blue jeans ripped`\n",
    "\n",
    "B. `blue navy shoes navy`\n",
    "\n",
    "C. `gym shoes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blue', 'gym', 'jeans', 'navy', 'ripped', 'shoes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>gym</th>\n",
       "      <th>jeans</th>\n",
       "      <th>navy</th>\n",
       "      <th>ripped</th>\n",
       "      <th>shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blue  gym  jeans  navy  ripped  shoes\n",
       "0     1    0      1     0       1      0\n",
       "1     1    0      0     2       0      1\n",
       "2     0    1      0     0       0      1"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your answer\n",
    "\n",
    "# creating term frequencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# edit these sentences to become less similar, and the similarity score should decrease\n",
    "data_corpus = [\"blue jeans ripped\", \n",
    "               \"blue navy shoes navy\",\n",
    "               \"gym shoes\",]\n",
    "\n",
    "X = vectorizer.fit_transform(data_corpus) \n",
    "X = X.toarray()\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "df = pd.DataFrame(columns = vectorizer.get_feature_names(),\n",
    "                  data = X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>gym</th>\n",
       "      <th>jeans</th>\n",
       "      <th>navy</th>\n",
       "      <th>ripped</th>\n",
       "      <th>shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df(t)</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blue  gym  jeans  navy  ripped  shoes\n",
       "0       1.0  0.0    1.0   0.0     1.0    0.0\n",
       "1       1.0  0.0    0.0   2.0     0.0    1.0\n",
       "2       0.0  1.0    0.0   0.0     0.0    1.0\n",
       "df(t)   2.0  1.0    1.0   1.0     1.0    2.0\n",
       "idf     1.0  1.5    1.5   1.5     1.5    1.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating doc frequency and idf\n",
    "df.loc['df(t)',:] = np.count_nonzero(df, axis=0)\n",
    "for i in df.columns:\n",
    "    df.loc['idf',i] = 3/(1 + df.loc['df(t)',i])\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>gym</th>\n",
       "      <th>jeans</th>\n",
       "      <th>navy</th>\n",
       "      <th>ripped</th>\n",
       "      <th>shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    blue  gym  jeans  navy  ripped  shoes\n",
       "d1   1.0  0.0    1.5   0.0     1.5    0.0\n",
       "d2   1.0  0.0    0.0   3.0     0.0    1.0\n",
       "d3   0.0  1.5    0.0   0.0     0.0    1.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating final tf.idf vectors!\n",
    "for i in range(3):\n",
    "    df.loc[f'd{i+1}',:] = df.loc[i,:]*df.loc['idf',:]\n",
    "\n",
    "tf_idf = df.loc[['d1','d2','d3'],:]\n",
    "tf_idf"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
